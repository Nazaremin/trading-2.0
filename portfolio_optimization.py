"""
–ú–æ–¥—É–ª—å –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏
–í–∫–ª—é—á–∞–µ—Ç:
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –ø–æ—Ä—Ç—Ñ–µ–ª—è –ø–æ –ú–∞—Ä–∫–æ–≤–∏—Ü—É
- Black-Litterman –º–æ–¥–µ–ª—å
- Risk Parity –ø–æ–¥—Ö–æ–¥
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏
- –ú–Ω–æ–≥–æ—Ñ–∞–∫—Ç–æ—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∏—Å–∫–∞
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import logging
from abc import ABC, abstractmethod
import warnings
warnings.filterwarnings('ignore')

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞
try:
    from scipy.optimize import minimize, differential_evolution
    from scipy import linalg
    from scipy.stats import norm, multivariate_normal
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    logging.warning("SciPy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install scipy")

# –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
try:
    import cvxpy as cp
    CVXPY_AVAILABLE = True
except ImportError:
    CVXPY_AVAILABLE = False
    logging.warning("CVXPY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install cvxpy")

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —ç–∫–æ–Ω–æ–º–µ—Ç—Ä–∏–∫–∞
try:
    from statsmodels.tsa.vector_ar.var_model import VAR
    from statsmodels.stats.correlation_tools import corr_nearest
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    logging.warning("Statsmodels –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install statsmodels")

@dataclass
class PortfolioConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
    optimization_method: str = "markowitz"  # markowitz, black_litterman, risk_parity, equal_weight
    risk_model: str = "sample"  # sample, factor, shrinkage
    rebalancing_frequency: str = "monthly"  # daily, weekly, monthly, quarterly
    max_weight: float = 0.3  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∞–∫—Ç–∏–≤–∞
    min_weight: float = 0.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–µ—Å –∞–∫—Ç–∏–≤–∞
    target_return: Optional[float] = None
    risk_aversion: float = 1.0
    transaction_costs: float = 0.001  # 0.1%
    lookback_period: int = 252  # –¥–Ω–µ–π –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
    confidence_level: float = 0.95

@dataclass
class Asset:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–∫—Ç–∏–≤–µ"""
    symbol: str
    name: str
    asset_class: str  # equity, bond, commodity, currency, crypto
    sector: Optional[str] = None
    country: Optional[str] = None
    market_cap: Optional[float] = None
    liquidity_score: float = 1.0
    esg_score: Optional[float] = None

@dataclass
class PortfolioMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
    expected_return: float
    volatility: float
    sharpe_ratio: float
    max_drawdown: float
    var_95: float  # Value at Risk
    cvar_95: float  # Conditional Value at Risk
    calmar_ratio: float
    sortino_ratio: float
    information_ratio: float
    tracking_error: float
    beta: float
    alpha: float
    weights: Dict[str, float]
    correlations: pd.DataFrame

@dataclass
class RiskFactors:
    """–§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞"""
    market_factor: float = 0.0
    size_factor: float = 0.0
    value_factor: float = 0.0
    momentum_factor: float = 0.0
    quality_factor: float = 0.0
    volatility_factor: float = 0.0
    currency_factor: float = 0.0
    sector_factors: Dict[str, float] = field(default_factory=dict)

class RiskModel(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∏—Å–∫–∞"""
    
    @abstractmethod
    def estimate_covariance(self, returns: pd.DataFrame) -> pd.DataFrame:
        """–û—Ü–µ–Ω–∫–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã"""
        pass
    
    @abstractmethod
    def estimate_expected_returns(self, returns: pd.DataFrame) -> pd.Series:
        """–û—Ü–µ–Ω–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π"""
        pass

class SampleRiskModel(RiskModel):
    """–í—ã–±–æ—Ä–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∏—Å–∫–∞"""
    
    def __init__(self, shrinkage_factor: float = 0.1):
        self.shrinkage_factor = shrinkage_factor
        self.logger = logging.getLogger("SampleRiskModel")
    
    def estimate_covariance(self, returns: pd.DataFrame) -> pd.DataFrame:
        """–û—Ü–µ–Ω–∫–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã —Å shrinkage"""
        sample_cov = returns.cov().values
        
        # Shrinkage –∫ –¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü–µ
        n_assets = sample_cov.shape[0]
        target = np.eye(n_assets) * np.trace(sample_cov) / n_assets
        
        shrunk_cov = (1 - self.shrinkage_factor) * sample_cov + self.shrinkage_factor * target
        
        return pd.DataFrame(shrunk_cov, index=returns.columns, columns=returns.columns)
    
    def estimate_expected_returns(self, returns: pd.DataFrame) -> pd.Series:
        """–û—Ü–µ–Ω–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π"""
        # –ü—Ä–æ—Å—Ç–æ–µ —Å—Ä–µ–¥–Ω–µ–µ —Å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π –Ω–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å
        mean_returns = returns.mean()
        volatilities = returns.std()
        
        # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Sharpe ratio
        sharpe_ratios = mean_returns / volatilities
        median_sharpe = sharpe_ratios.median()
        
        # Shrinkage –∫ –º–µ–¥–∏–∞–Ω–Ω–æ–º—É Sharpe ratio
        adjusted_returns = volatilities * median_sharpe * 0.5 + mean_returns * 0.5
        
        return adjusted_returns

class FactorRiskModel(RiskModel):
    """–§–∞–∫—Ç–æ—Ä–Ω–∞—è –º–æ–¥–µ–ª—å —Ä–∏—Å–∫–∞"""
    
    def __init__(self, factors: List[str] = None):
        if factors is None:
            factors = ['market', 'size', 'value', 'momentum']
        self.factors = factors
        self.factor_loadings = {}
        self.factor_returns = None
        self.specific_risks = None
        self.logger = logging.getLogger("FactorRiskModel")
    
    def fit_factor_model(self, returns: pd.DataFrame, factor_returns: pd.DataFrame):
        """–ü–æ–¥–≥–æ–Ω–∫–∞ —Ñ–∞–∫—Ç–æ—Ä–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        self.factor_returns = factor_returns
        self.factor_loadings = {}
        self.specific_risks = {}
        
        for asset in returns.columns:
            # –†–µ–≥—Ä–µ—Å—Å–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –∞–∫—Ç–∏–≤–∞ –Ω–∞ —Ñ–∞–∫—Ç–æ—Ä—ã
            y = returns[asset].dropna()
            X = factor_returns.loc[y.index]
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
            X = X.copy()
            X['const'] = 1.0
            
            try:
                # OLS —Ä–µ–≥—Ä–µ—Å—Å–∏—è
                beta = np.linalg.lstsq(X.values, y.values, rcond=None)[0]
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–Ω—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
                self.factor_loadings[asset] = dict(zip(X.columns, beta))
                
                # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫
                predicted = X.values @ beta
                residuals = y.values - predicted
                self.specific_risks[asset] = np.var(residuals)
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –¥–ª—è {asset}: {e}")
                # Fallback –∑–Ω–∞—á–µ–Ω–∏—è
                self.factor_loadings[asset] = {factor: 0.0 for factor in self.factors}
                self.factor_loadings[asset]['const'] = 0.0
                self.specific_risks[asset] = returns[asset].var()
    
    def estimate_covariance(self, returns: pd.DataFrame) -> pd.DataFrame:
        """–û—Ü–µ–Ω–∫–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã —á–µ—Ä–µ–∑ —Ñ–∞–∫—Ç–æ—Ä–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not self.factor_loadings:
            # Fallback –∫ –≤—ã–±–æ—Ä–æ—á–Ω–æ–π –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–∏
            return returns.cov()
        
        assets = returns.columns
        n_assets = len(assets)
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ —Ñ–∞–∫—Ç–æ—Ä–Ω—ã—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
        B = np.zeros((n_assets, len(self.factors)))
        for i, asset in enumerate(assets):
            for j, factor in enumerate(self.factors):
                B[i, j] = self.factor_loadings.get(asset, {}).get(factor, 0.0)
        
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        if self.factor_returns is not None:
            F = self.factor_returns[self.factors].cov().values
        else:
            F = np.eye(len(self.factors)) * 0.01  # Fallback
        
        # –î–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —Ä–∏—Å–∫–æ–≤
        D = np.diag([self.specific_risks.get(asset, 0.01) for asset in assets])
        
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞: B * F * B' + D
        cov_matrix = B @ F @ B.T + D
        
        return pd.DataFrame(cov_matrix, index=assets, columns=assets)
    
    def estimate_expected_returns(self, returns: pd.DataFrame) -> pd.Series:
        """–û—Ü–µ–Ω–∫–∞ –æ–∂–∏–¥–∞–µ–º—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ —Ñ–∞–∫—Ç–æ—Ä–Ω—É—é –º–æ–¥–µ–ª—å"""
        if not self.factor_loadings or self.factor_returns is None:
            return returns.mean()
        
        # –û–∂–∏–¥–∞–µ–º—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        factor_expected_returns = self.factor_returns[self.factors].mean()
        
        expected_returns = {}
        for asset in returns.columns:
            loadings = self.factor_loadings.get(asset, {})
            expected_return = sum(
                loadings.get(factor, 0.0) * factor_expected_returns.get(factor, 0.0)
                for factor in self.factors
            )
            expected_returns[asset] = expected_return
        
        return pd.Series(expected_returns)

class PortfolioOptimizer:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
    
    def __init__(self, config: PortfolioConfig):
        self.config = config
        self.logger = logging.getLogger("PortfolioOptimizer")
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —Ä–∏—Å–∫–∞
        if config.risk_model == "factor":
            self.risk_model = FactorRiskModel()
        else:
            self.risk_model = SampleRiskModel()
    
    def optimize_portfolio(self, returns: pd.DataFrame, 
                          market_views: Optional[Dict[str, float]] = None,
                          benchmark_weights: Optional[Dict[str, float]] = None) -> Dict[str, float]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        
        if self.config.optimization_method == "markowitz":
            return self._optimize_markowitz(returns)
        elif self.config.optimization_method == "black_litterman":
            return self._optimize_black_litterman(returns, market_views, benchmark_weights)
        elif self.config.optimization_method == "risk_parity":
            return self._optimize_risk_parity(returns)
        elif self.config.optimization_method == "equal_weight":
            return self._optimize_equal_weight(returns)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {self.config.optimization_method}")
    
    def _optimize_markowitz(self, returns: pd.DataFrame) -> Dict[str, float]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ –ú–∞—Ä–∫–æ–≤–∏—Ü—É"""
        # –û—Ü–µ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        expected_returns = self.risk_model.estimate_expected_returns(returns)
        cov_matrix = self.risk_model.estimate_covariance(returns)
        
        n_assets = len(returns.columns)
        
        # –¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –º–∞–∫—Å–∏–º–∏–∑–∞—Ü–∏—è utility = return - 0.5 * risk_aversion * risk
        def objective(weights):
            portfolio_return = np.dot(weights, expected_returns)
            portfolio_risk = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights)))
            return -(portfolio_return - 0.5 * self.config.risk_aversion * portfolio_risk ** 2)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        constraints = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}  # –°—É–º–º–∞ –≤–µ—Å–æ–≤ = 1
        ]
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
        if self.config.target_return is not None:
            constraints.append({
                'type': 'eq',
                'fun': lambda w: np.dot(w, expected_returns) - self.config.target_return
            })
        
        # –ì—Ä–∞–Ω–∏—Ü—ã –≤–µ—Å–æ–≤
        bounds = [(self.config.min_weight, self.config.max_weight) for _ in range(n_assets)]
        
        # –ù–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
        x0 = np.array([1.0 / n_assets] * n_assets)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        try:
            result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)
            
            if result.success:
                weights = dict(zip(returns.columns, result.x))
                return {k: max(0, v) for k, v in weights.items()}  # –£–±–∏—Ä–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –≤–µ—Å–∞
            else:
                self.logger.warning("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –Ω–µ —Å–æ—à–ª–∞—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω—ã–µ –≤–µ—Å–∞")
                return self._optimize_equal_weight(returns)
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ú–∞—Ä–∫–æ–≤–∏—Ü–∞: {e}")
            return self._optimize_equal_weight(returns)
    
    def _optimize_black_litterman(self, returns: pd.DataFrame,
                                 market_views: Optional[Dict[str, float]] = None,
                                 benchmark_weights: Optional[Dict[str, float]] = None) -> Dict[str, float]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Black-Litterman"""
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Ä—ã–Ω–æ—á–Ω—ã—Ö –≤–µ—Å–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–≤–Ω—ã–µ
        if benchmark_weights is None:
            benchmark_weights = {asset: 1.0/len(returns.columns) for asset in returns.columns}
        
        # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        cov_matrix = self.risk_model.estimate_covariance(returns).values
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –≤–µ—Å–∞
        w_market = np.array([benchmark_weights.get(asset, 0) for asset in returns.columns])
        
        # –ü–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ–º—ã–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (reverse optimization)
        risk_aversion = self.config.risk_aversion
        implied_returns = risk_aversion * np.dot(cov_matrix, w_market)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –≤–∑–≥–ª—è–¥—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
        if market_views:
            # –ú–∞—Ç—Ä–∏—Ü–∞ P (–∫–∞–∫–∏–µ –∞–∫—Ç–∏–≤—ã –∑–∞—Ç—Ä–∞–≥–∏–≤–∞—é—Ç –≤–∑–≥–ª—è–¥—ã)
            views_assets = list(market_views.keys())
            P = np.zeros((len(views_assets), len(returns.columns)))
            Q = np.zeros(len(views_assets))  # –í–µ–∫—Ç–æ—Ä –≤–∑–≥–ª—è–¥–æ–≤
            
            for i, asset in enumerate(views_assets):
                if asset in returns.columns:
                    asset_idx = list(returns.columns).index(asset)
                    P[i, asset_idx] = 1.0
                    Q[i] = market_views[asset]
            
            # –ú–∞—Ç—Ä–∏—Ü–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏ –≤–∑–≥–ª—è–¥–æ–≤ (Omega)
            Omega = np.eye(len(views_assets)) * 0.01  # 1% –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä tau (–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å prior)
            tau = 1.0 / len(returns)
            
            # Black-Litterman —Ñ–æ—Ä–º—É–ª–∞
            try:
                M1 = linalg.inv(tau * cov_matrix)
                M2 = np.dot(P.T, np.dot(linalg.inv(Omega), P))
                M3 = np.dot(linalg.inv(tau * cov_matrix), implied_returns)
                M4 = np.dot(P.T, np.dot(linalg.inv(Omega), Q))
                
                # –ù–æ–≤—ã–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                mu_bl = np.dot(linalg.inv(M1 + M2), M3 + M4)
                
                # –ù–æ–≤–∞—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
                cov_bl = linalg.inv(M1 + M2)
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ –≤ Black-Litterman: {e}")
                mu_bl = implied_returns
                cov_bl = cov_matrix
        else:
            mu_bl = implied_returns
            cov_bl = cov_matrix
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        def objective(weights):
            portfolio_return = np.dot(weights, mu_bl)
            portfolio_risk = np.sqrt(np.dot(weights, np.dot(cov_bl, weights)))
            return -(portfolio_return - 0.5 * risk_aversion * portfolio_risk ** 2)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –≥—Ä–∞–Ω–∏—Ü—ã
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
        bounds = [(self.config.min_weight, self.config.max_weight) for _ in range(len(returns.columns))]
        x0 = w_market
        
        try:
            result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)
            
            if result.success:
                return dict(zip(returns.columns, result.x))
            else:
                return dict(zip(returns.columns, w_market))
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Black-Litterman: {e}")
            return dict(zip(returns.columns, w_market))
    
    def _optimize_risk_parity(self, returns: pd.DataFrame) -> Dict[str, float]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Risk Parity"""
        cov_matrix = self.risk_model.estimate_covariance(returns).values
        n_assets = len(returns.columns)
        
        def risk_budget_objective(weights):
            """–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Risk Parity"""
            weights = np.array(weights)
            portfolio_vol = np.sqrt(np.dot(weights, np.dot(cov_matrix, weights)))
            
            # –ú–∞—Ä–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–∫–ª–∞–¥ –≤ —Ä–∏—Å–∫
            marginal_contrib = np.dot(cov_matrix, weights) / portfolio_vol
            
            # –í–∫–ª–∞–¥ –≤ —Ä–∏—Å–∫
            contrib = weights * marginal_contrib
            
            # –¶–µ–ª–µ–≤–æ–π –≤–∫–ª–∞–¥ (—Ä–∞–≤–Ω—ã–π –¥–ª—è –≤—Å–µ—Ö –∞–∫—Ç–∏–≤–æ–≤)
            target_contrib = portfolio_vol / n_assets
            
            # –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Ä–∞–≤–Ω–æ–≥–æ –≤–∫–ª–∞–¥–∞
            return np.sum((contrib - target_contrib) ** 2)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}]
        bounds = [(self.config.min_weight, self.config.max_weight) for _ in range(n_assets)]
        
        # –ù–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ - –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        initial_weights = 1.0 / np.diag(cov_matrix)
        initial_weights = initial_weights / np.sum(initial_weights)
        
        try:
            result = minimize(risk_budget_objective, initial_weights, 
                            method='SLSQP', bounds=bounds, constraints=constraints)
            
            if result.success:
                return dict(zip(returns.columns, result.x))
            else:
                return self._optimize_equal_weight(returns)
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Risk Parity: {e}")
            return self._optimize_equal_weight(returns)
    
    def _optimize_equal_weight(self, returns: pd.DataFrame) -> Dict[str, float]:
        """–†–∞–≤–Ω–æ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –ø–æ—Ä—Ç—Ñ–µ–ª—å"""
        n_assets = len(returns.columns)
        equal_weight = 1.0 / n_assets
        return {asset: equal_weight for asset in returns.columns}

class CorrelationManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
    
    def __init__(self, lookback_window: int = 252):
        self.lookback_window = lookback_window
        self.logger = logging.getLogger("CorrelationManager")
    
    def calculate_dynamic_correlations(self, returns: pd.DataFrame, 
                                     method: str = "ewm") -> pd.DataFrame:
        """–†–∞—Å—á–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
        
        if method == "ewm":
            # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            return returns.ewm(span=self.lookback_window).corr().iloc[-len(returns.columns):]
        
        elif method == "rolling":
            # –°–∫–æ–ª—å–∑—è—â–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            return returns.rolling(window=self.lookback_window).corr().iloc[-len(returns.columns):]
        
        elif method == "dcc":
            # Dynamic Conditional Correlation (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            return self._calculate_dcc(returns)
        
        else:
            # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            return returns.corr()
    
    def _calculate_dcc(self, returns: pd.DataFrame) -> pd.DataFrame:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è DCC –º–æ–¥–µ–ª—å"""
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        standardized_returns = returns / returns.rolling(window=22).std()
        
        # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        ewm_corr = standardized_returns.ewm(span=60).corr()
        
        return ewm_corr.iloc[-len(returns.columns):]
    
    def detect_correlation_regimes(self, returns: pd.DataFrame, 
                                  window: int = 60) -> pd.Series:
        """–î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ–∂–∏–º–æ–≤ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
        rolling_corr = []
        
        for i in range(window, len(returns)):
            subset = returns.iloc[i-window:i]
            avg_corr = subset.corr().values[np.triu_indices_from(subset.corr().values, k=1)].mean()
            rolling_corr.append(avg_corr)
        
        corr_series = pd.Series(rolling_corr, index=returns.index[window:])
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–≤–∞–Ω—Ç–∏–ª–µ–π
        low_threshold = corr_series.quantile(0.33)
        high_threshold = corr_series.quantile(0.67)
        
        regimes = pd.Series(index=corr_series.index, dtype=str)
        regimes[corr_series <= low_threshold] = "low_correlation"
        regimes[(corr_series > low_threshold) & (corr_series <= high_threshold)] = "medium_correlation"
        regimes[corr_series > high_threshold] = "high_correlation"
        
        return regimes
    
    def calculate_correlation_risk(self, weights: Dict[str, float], 
                                  correlations: pd.DataFrame) -> float:
        """–†–∞—Å—á–µ—Ç —Ä–∏—Å–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π"""
        
        assets = list(weights.keys())
        weight_vector = np.array([weights[asset] for asset in assets])
        
        # –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
        corr_matrix = correlations.loc[assets, assets].values
        
        # –£–±–∏—Ä–∞–µ–º –¥–∏–∞–≥–æ–Ω–∞–ª—å (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Å–∞–º–∏–º —Å–æ–±–æ–π)
        mask = ~np.eye(corr_matrix.shape[0], dtype=bool)
        avg_correlation = np.average(corr_matrix[mask], weights=np.outer(weight_vector, weight_vector)[mask])
        
        return avg_correlation

class PortfolioAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
    
    def __init__(self):
        self.logger = logging.getLogger("PortfolioAnalyzer")
    
    def calculate_portfolio_metrics(self, returns: pd.DataFrame, 
                                   weights: Dict[str, float],
                                   benchmark_returns: Optional[pd.Series] = None,
                                   risk_free_rate: float = 0.02) -> PortfolioMetrics:
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        
        # –î–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        portfolio_returns = self._calculate_portfolio_returns(returns, weights)
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        expected_return = portfolio_returns.mean() * 252
        volatility = portfolio_returns.std() * np.sqrt(252)
        sharpe_ratio = (expected_return - risk_free_rate) / volatility if volatility > 0 else 0
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞
        cumulative_returns = (1 + portfolio_returns).cumprod()
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max
        max_drawdown = drawdown.min()
        
        # Value at Risk –∏ Conditional VaR
        var_95 = np.percentile(portfolio_returns, 5)
        cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean()
        
        # Calmar ratio
        calmar_ratio = expected_return / abs(max_drawdown) if max_drawdown != 0 else 0
        
        # Sortino ratio
        downside_returns = portfolio_returns[portfolio_returns < 0]
        downside_deviation = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
        sortino_ratio = (expected_return - risk_free_rate) / downside_deviation if downside_deviation > 0 else 0
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–µ–Ω—á–º–∞—Ä–∫–∞
        if benchmark_returns is not None:
            excess_returns = portfolio_returns - benchmark_returns
            tracking_error = excess_returns.std() * np.sqrt(252)
            information_ratio = excess_returns.mean() * 252 / tracking_error if tracking_error > 0 else 0
            
            # Beta –∏ Alpha
            covariance = np.cov(portfolio_returns, benchmark_returns)[0, 1]
            benchmark_variance = benchmark_returns.var()
            beta = covariance / benchmark_variance if benchmark_variance > 0 else 0
            alpha = (expected_return - risk_free_rate) - beta * (benchmark_returns.mean() * 252 - risk_free_rate)
        else:
            tracking_error = 0
            information_ratio = 0
            beta = 0
            alpha = 0
        
        # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
        correlations = returns[list(weights.keys())].corr()
        
        return PortfolioMetrics(
            expected_return=expected_return,
            volatility=volatility,
            sharpe_ratio=sharpe_ratio,
            max_drawdown=max_drawdown,
            var_95=var_95,
            cvar_95=cvar_95,
            calmar_ratio=calmar_ratio,
            sortino_ratio=sortino_ratio,
            information_ratio=information_ratio,
            tracking_error=tracking_error,
            beta=beta,
            alpha=alpha,
            weights=weights,
            correlations=correlations
        )
    
    def _calculate_portfolio_returns(self, returns: pd.DataFrame, 
                                   weights: Dict[str, float]) -> pd.Series:
        """–†–∞—Å—á–µ—Ç –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –ø–æ—Ä—Ç—Ñ–µ–ª—è"""
        portfolio_returns = pd.Series(0, index=returns.index)
        
        for asset, weight in weights.items():
            if asset in returns.columns:
                portfolio_returns += weight * returns[asset]
        
        return portfolio_returns
    
    def calculate_efficient_frontier(self, returns: pd.DataFrame, 
                                   n_portfolios: int = 100) -> Tuple[np.ndarray, np.ndarray]:
        """–†–∞—Å—á–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü—ã"""
        
        expected_returns = returns.mean() * 252
        cov_matrix = returns.cov() * 252
        
        # –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–ª–µ–≤—ã—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
        min_ret = expected_returns.min()
        max_ret = expected_returns.max()
        target_returns = np.linspace(min_ret, max_ret, n_portfolios)
        
        efficient_portfolios = []
        
        for target_ret in target_returns:
            try:
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–ª–µ–≤–æ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
                n_assets = len(returns.columns)
                
                def objective(weights):
                    return np.sqrt(np.dot(weights, np.dot(cov_matrix, weights)))
                
                constraints = [
                    {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},
                    {'type': 'eq', 'fun': lambda w: np.dot(w, expected_returns) - target_ret}
                ]
                
                bounds = [(0, 1) for _ in range(n_assets)]
                x0 = np.array([1.0 / n_assets] * n_assets)
                
                result = minimize(objective, x0, method='SLSQP', bounds=bounds, constraints=constraints)
                
                if result.success:
                    portfolio_return = np.dot(result.x, expected_returns)
                    portfolio_risk = np.sqrt(np.dot(result.x, np.dot(cov_matrix, result.x)))
                    efficient_portfolios.append((portfolio_risk, portfolio_return))
                
            except Exception as e:
                self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ {target_ret}: {e}")
        
        if efficient_portfolios:
            risks, returns_eff = zip(*efficient_portfolios)
            return np.array(risks), np.array(returns_eff)
        else:
            return np.array([]), np.array([])

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def demo_portfolio_optimization():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    
    print("üìä –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–û–†–¢–§–ï–õ–¨–ù–û–ô –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò")
    print("=" * 60)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')
    
    # –°–∏–º—É–ª—è—Ü–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π –¥–ª—è 5 –∞–∫—Ç–∏–≤–æ–≤
    assets = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']
    n_assets = len(assets)
    
    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    correlation_matrix = np.array([
        [1.00, 0.60, 0.65, 0.30, 0.55],
        [0.60, 1.00, 0.70, 0.25, 0.60],
        [0.65, 0.70, 1.00, 0.20, 0.50],
        [0.30, 0.25, 0.20, 1.00, 0.35],
        [0.55, 0.60, 0.50, 0.35, 1.00]
    ])
    
    # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
    volatilities = np.array([0.25, 0.28, 0.22, 0.45, 0.30])
    
    # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    cov_matrix = np.outer(volatilities, volatilities) * correlation_matrix
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
    mean_returns = np.array([0.12, 0.10, 0.11, 0.15, 0.13]) / 252  # –î–Ω–µ–≤–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
    
    returns_data = np.random.multivariate_normal(mean_returns, cov_matrix / 252, len(dates))
    returns_df = pd.DataFrame(returns_data, index=dates, columns=assets)
    
    print(f"üìà –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(assets)} –∞–∫—Ç–∏–≤–æ–≤ –∑–∞ {len(dates)} –¥–Ω–µ–π")
    print(f"   –ê–∫—Ç–∏–≤—ã: {', '.join(assets)}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
    config = PortfolioConfig(
        optimization_method="markowitz",
        max_weight=0.4,
        min_weight=0.05,
        risk_aversion=2.0
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    optimizer = PortfolioOptimizer(config)
    
    print(f"\nüîß –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è –º–µ—Ç–æ–¥–æ–º: {config.optimization_method}")
    
    try:
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—è
        optimal_weights = optimizer.optimize_portfolio(returns_df)
        
        print(f"‚úÖ –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞ –ø–æ—Ä—Ç—Ñ–µ–ª—è:")
        for asset, weight in optimal_weights.items():
            print(f"   {asset}: {weight:.1%}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Ä—Ç—Ñ–µ–ª—è
        analyzer = PortfolioAnalyzer()
        metrics = analyzer.calculate_portfolio_metrics(returns_df, optimal_weights)
        
        print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è:")
        print(f"   –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {metrics.expected_return:.1%}")
        print(f"   –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {metrics.volatility:.1%}")
        print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {metrics.sharpe_ratio:.2f}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {metrics.max_drawdown:.1%}")
        print(f"   VaR (95%): {metrics.var_95:.1%}")
        print(f"   –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ö–∞–ª—å–º–∞—Ä–∞: {metrics.calmar_ratio:.2f}")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ä–∞–≤–Ω–æ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–º –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º
        equal_weights = {asset: 1.0/len(assets) for asset in assets}
        equal_metrics = analyzer.calculate_portfolio_metrics(returns_df, equal_weights)
        
        print(f"\n‚öñÔ∏è –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Ä–∞–≤–Ω–æ–≤–∑–≤–µ—à–µ–Ω–Ω—ã–º –ø–æ—Ä—Ç—Ñ–µ–ª–µ–º:")
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ Sharpe ratio: {(metrics.sharpe_ratio - equal_metrics.sharpe_ratio):.2f}")
        print(f"   –°–Ω–∏–∂–µ–Ω–∏–µ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: {(equal_metrics.volatility - metrics.volatility):.1%}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
        corr_manager = CorrelationManager()
        correlations = corr_manager.calculate_dynamic_correlations(returns_df, method="ewm")
        
        print(f"\nüîó –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π:")
        avg_correlation = correlations.values[np.triu_indices_from(correlations.values, k=1)].mean()
        print(f"   –°—Ä–µ–¥–Ω—è—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {avg_correlation:.2f}")
        
        correlation_risk = corr_manager.calculate_correlation_risk(optimal_weights, correlations)
        print(f"   –†–∏—Å–∫ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø–æ—Ä—Ç—Ñ–µ–ª—è: {correlation_risk:.2f}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–æ–≤:")
        
        methods = ["risk_parity", "equal_weight"]
        for method in methods:
            config.optimization_method = method
            test_optimizer = PortfolioOptimizer(config)
            test_weights = test_optimizer.optimize_portfolio(returns_df)
            test_metrics = analyzer.calculate_portfolio_metrics(returns_df, test_weights)
            
            print(f"   {method.replace('_', ' ').title()}:")
            print(f"     Sharpe ratio: {test_metrics.sharpe_ratio:.2f}")
            print(f"     –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å: {test_metrics.volatility:.1%}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ—Ä—Ç—Ñ–µ–ª—è: {e}")
    
    print("\n" + "=" * 60)
    print("‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ—Ä—Ç—Ñ–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO)
    
    # –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    demo_portfolio_optimization()

